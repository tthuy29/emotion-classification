{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"main-CNN-Fea_Word.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"k7Uzv-ZSEUb1","colab_type":"code","colab":{}},"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","df = pd.read_excel('drive/colab/isear.xls', names = ['EMOTION', 'TEXT','EMOTION2'])\n","target_data = df['EMOTION']\n","text = df['TEXT']\n","\n","from nltk.tokenize import word_tokenize\n","import nltk\n","nltk.download('punkt')\n","\n","vecto_len = 300\n","max_len = 60\n","len_matrix = len(target_data)\n","len_tr = int(len_matrix*80/100)\n","len_tst = len_matrix-len_tr\n","print(len_tr)\n","print(len_tst)\n","f3 = open('drive/colab/x_train_300.txt','r',encoding='utf-8')\n","x_tr = [[[0 for i in range(vecto_len)]for j in range (max_len)] for k in range(len_tr)]\n","k = 0\n","j = 0\n","for line in f3:\n","    line = line.split()\n","    for i in range(vecto_len):\n","        x_tr[k][j][i] = float(line[i])\n","    j = j+1\n","    if j == max_len:\n","        k = k+1\n","        j = 0\n","f3.close()\n","f = open('drive/colab/x_train_fea_300.txt', 'r', encoding = 'utf-8')\n","x_tr_fea = [[[0 for i in range(vecto_len)] for j in range(max_len)] for k in range(len_tr)]\n","k = 0\n","j = 0\n","for line in f:\n","    line = line.split()\n","    for i in range(vecto_len):\n","         x_tr_fea[k][j][i] = float(line[i])\n","    j = j + 1\n","    if j == max_len:\n","        k = k + 1\n","        j = 0\n","f.close()\n","\n","f = open ('drive/colab/x_tr_fea_600.txt','w',encoding = 'utf-8')\n","for i in range(len_tr):\n","    for j in range(max_len):\n","        for k in range(vecto_len):\n","            f.write(str(x_tr[i][j][k])+' ')\n","        for k in range(vecto_len):\n","            f.write(str(x_tr_fea[i][j][k])+' ')\n","        f.write('\\n')\n","    print(i)\n","f.close()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7zAHuPjSKbgu","colab_type":"code","colab":{}},"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","df = pd.read_excel('drive/colab/isear.xls', names = ['EMOTION', 'TEXT','EMOTION2'])\n","target_data = df['EMOTION']\n","text = df['TEXT']\n","\n","from nltk.tokenize import word_tokenize\n","import nltk\n","nltk.download('punkt')\n","\n","vecto_len = 300\n","max_len = 60\n","len_matrix = len(target_data)\n","en_tr = int(len_matrix*80/100)\n","len_tst = len_matrix-len_tr\n","f4 = open('drive/colab/x_test_300.txt', 'r', encoding='utf-8')\n","x_tst = [[[0 for i in range(vecto_len)] for j in range(max_len)] for k in range(len_tst)]\n","k = 0\n","j = 0\n","for line in f4:\n","    line = line.split()\n","    for i in range(vecto_len):\n","         x_tst[k][j][i] = float(line[i])\n","    j = j + 1\n","    if j == max_len:\n","        k = k + 1\n","        j = 0\n","f4.close()\n","\n","f = open('drive/colab/x_test_fea_300.txt', 'r', encoding = 'utf-8')\n","x_tst_fea = [[[0 for i in range(vecto_len)] for j in range(max_len)] for k in range(len_tst)]\n","k = 0\n","j = 0\n","for line in f:\n","    line = line.split()\n","    for i in range(vecto_len):\n","         x_tst_fea[k][j][i] = float(line[i])\n","    j = j + 1\n","    if j == max_len:\n","        k = k + 1\n","        j = 0\n","f.close()\n","\n","f = open ('drive/colab/x_tst_fea_600.txt','w',encoding = 'utf-8')\n","for i in range(len_tst):\n","    for j in range(max_len):\n","        for k in range(vecto_len):\n","            f.write(str(x_tst[i][j][k])+' ')\n","        for k in range(vecto_len):\n","            f.write(str(x_tst_fea[i][j][k])+' ')\n","        f.write('\\n')\n","    print(i)\n","f.close()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JOIw4Wa11a_J","colab_type":"code","colab":{}},"cell_type":"code","source":["import pandas as pd\n","df = pd.read_excel('drive/colab/isear.xls', names = ['EMOTION', 'TEXT','EMOTION2'])\n","target_data = df['EMOTION']\n","text = df['TEXT']\n","\n","from nltk.tokenize import word_tokenize\n","import nltk\n","nltk.download('punkt')\n","\n","\n","from keras.utils import to_categorical\n","from keras.models import Model\n","from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, Input, Concatenate,GlobalMaxPooling1D, AveragePooling1D, GlobalMaxPooling1D\n","from keras import layers\n","import keras\n","import keras.utils\n","from keras import utils as np_utils\n","import numpy as np\n","import itertools\n","from keras.callbacks import ModelCheckpoint\n","\n","y_tr_data = []\n","y_tst_data = []\n","f = open('drive/colab/y_tr.txt', 'r', encoding = 'utf-8')\n","for l in f:\n","  l = l.split()\n","  y_tr_data.append(int(l[0]))\n","f.close()\n","f = open('drive/colab/y_tst.txt', 'r', encoding = 'utf-8')\n","for l in f:\n","  l = l.split()\n","  y_tst_data.append(int(l[0]))\n","f.close()\n","\n","vecto_len = 600\n","max_len = 60\n","len_matrix = len(target_data)\n","len_tr = len(y_tr_data)\n","len_tst = len(y_tst_data)\n","\n","for i in range(len(y_tr_data)):\n","    y_tr_data[i] = y_tr_data[i] - 1\n","for j in range(len(y_tst_data)):\n","    y_tst_data[j] = y_tst_data[j] - 1\n","\n","classes = np.max(y_tr_data)+1\n","y_tr_data = to_categorical(y_tr_data,classes)\n","y_tst_data = to_categorical(y_tst_data,classes)\n","y_tr_data = np.array(y_tr_data)\n","y_tst_data = np.array(y_tst_data)\n","\n","f = open('drive/colab/x_tr_fea_600.txt', 'r', encoding = 'utf-8')\n","x_tr_fea = [[[0 for i in range(vecto_len)] for j in range(max_len)] for k in range(len_tr)]\n","k = 0\n","j = 0\n","for line in f:\n","    line = line.split()\n","    for i in range(vecto_len):\n","         x_tr_fea[k][j][i] = float(line[i])\n","    j = j + 1\n","    if j == max_len:\n","        k = k + 1\n","        j = 0\n","f.close()\n","x_tr_fea = np.array(x_tr_fea)\n","\n","f = open('drive/colab/x_tst_fea_600.txt', 'r', encoding = 'utf-8')\n","x_tst_fea = [[[0 for i in range(vecto_len)] for j in range(max_len)] for k in range(len_tst)]\n","k = 0\n","j = 0\n","for line in f:\n","    line = line.split()\n","    for i in range(vecto_len):\n","         x_tst_fea[k][j][i] = float(line[i])\n","    j = j + 1\n","    if j == max_len:\n","        k = k + 1\n","        j = 0\n","f.close()\n","\n","x_tst_fea = np.array(x_tst_fea)\n","\n","import matplotlib.pyplot as plt\n","x_input = Input(shape=(max_len, vecto_len),dtype='float')\n","x = Conv1D(filters= 256, kernel_size= 2,activation='relu')(x_input)\n","x = GlobalMaxPooling1D()(x)\n","x = Dense(128,activation='relu')(x)\n","x = Dropout(0.05)(x)\n","out = Dense(units=classes,activation='softmax')(x)\n","model = Model(inputs=x_input,outputs= out)\n","model.compile(loss='mean_squared_error',optimizer='adam',metrics=['acc'])\n","batch_size = 128\n","epochs = 50\n","model.fit(x_tr_fea, y_tr_data, batch_size = batch_size,  epochs = epochs, verbose = 1)\n","score = model.evaluate(x_tst_fea,y_tst_data, verbose=0)\n","print('Test accuracy:', score[1])\n"],"execution_count":0,"outputs":[]}]}